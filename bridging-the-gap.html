<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Bridging the Gap</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Kai'lani Woodard</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Back to Main</a></li>
							<li><a href="research-notebook.html">Research Notebook</a></li>
							<li class="active"><a href="bridging-the-gap.html">Bridging the Gap</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/kailani-woodard/" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/kailaniwoodard" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>Bridging<br />
									the Gap: Facial Recognition?</h1>
									<p>Exploration into the new.</p>
								</header>
								<h2>Out with the Old and in with the New...</h2>
									<p>Since beginning junior seminar, I have certainly undergone quite the journey
                  in regards to knowing where I was at for my proposed research at any given
                  time, spending a majority of my time wondering if I was gonna land on my
                  feet...</p>
									<p>With that being said, this particular post stands as a landmark to declare
                  the change from my focus of trying to force my personal project into fitting
                  into this category.</p>
									<p>That being said, without further ado, I will be discussing the knowledge
                  gap that I have observed with my current proposed research.</p>
								<h2>The Gap</h2>
									<p>Since moving from pursuit of beautiful data visualizations powered by
                  Spotify, I have shifted focus to ultimately wanting to utilize the ability
                  to use facial recognition and eye tracking to manipulate art while someone
                  is viewing it.</p>
									<p>Part of my gap I discovered recently lies with facial recognition in tandem with
                  emotions that discussed some gaps that are concerned with the larger scale
                  of the foundation of the facial tracking that I have decided to employ.</p>
                  <p>Additionally, reading and analyzing eye tracking movements and attributing
                  certain behaviors to be able to interpret the viewer or consumer's impression
                  of the media put before them.</p>
								<h2>Validating the Gap</h2>
									<p>Identifying that there was a verifiable gap in knowledge regarding my intended
                  scope of study was rather easy. Simply verifying that the questions that I had
                  were not quite answered with searching and only having little or nearly no information
                  available to explain was a huge indicator.</p>
				          <p>In some rather lightweight research to attempt to bridge this gap, I found a few
                  great resources to begin pointing me and other researchers with likeminded goals to
                  feel more able to understand what questions to ask and how to move forward. I read
                  a couple of rather informational journal entries and articles that helped me grasp
                  these ideas better.</p>
									<p>These resources will be credited at the end if you would like to refer to them.</p>
								<h2>What Questions Do I Have?</h2>
									<p>After completion of some light research, I felt left with mostly questions that
                  pertained to the behaviorial phenomenon with eye movement and data collection of the
                  paths created by eye tracking, these being:</p>
									<p><b>How do specific patterns of eye movement correlate to perceptions of what is being viewed?</b></p>
                  <p><b>How can I use the data recorded from eye movement to generate some sort of modification to the visual being observed?</b></p>
									<p>Only through further conduct of research mixed with experimentation will bring me
                    the answers, the missing pieces to help construct and bridge this gap.</p>
								<h2>Referenced Articles</h2>
									<p>Susillo Ridao, Alejandro, et al. “A Comparison of Tools and Libraries for
                  In-Class Face Detection and Emotion Recognition.” <i>Association for Computing
                    Machinery</i>, 2020, pp. 295. https://doi.org/10.1145/3368308.3415427.</p>
                  <p>Azlina Mansor, Aida, et al. “The Impact of Eye Tracking on Neuromarketing
                    for Genuine Value-Added Applications.” <i>Global Business and Management
                      Research: An International Journal</i>, vol. 10, no. 1, 2018, pp. 1-9.
                      https://d1wqtxts1xzle7.cloudfront.net/57680227/V10N1_1-with-cover-page-v2.pdf?Expires=1656554269&Signature=D94I081kof-VbYlh6cYNggZeQQ6IwWiyDtwNDd6K9nzZqnc2DDJiFQxHlFF-vvrIos14o4PMLw1tzmuXGPhWKfQD6by2ljYhhS3Dpe9Z1UVa9LSnaZ4g5c1CyPDi6JHiVkwSllqvvLstG22ZMY5Ym14NO~qK09rEbI-tYyGUWZEexlFMY0rw2ID7kclXZnxhCyiii~~zzdGAJZY0~lO3Bij4GPXz1qHEMSuKVkxnCi83IiLI9cOy8Ge02F9FIf8NSbOmHF~cn13L785IEOQv4Jisc5XPs17SQTmrWKio38OWg3RA51hmFExUXhi8CLPdzsxWoiUh4E2S6MRdgjD0qQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA.</p>
                    <p>Huang, Michael Xuelin, et al. “Building a Personalized, Auto-Calibrating
                    Eye Tracker from User Interactions.” <i>Association for Computing Machinery</i>,
                      2016, pp. 5169-5178. https://doi.org/10.1145/2858036.2858404.</p>
                    <p>Kassner, Moritz, et al. “Pupil: an open source platform for pervasive
                    eye tracking and mobile gaze-based interaction.” <i>Association for Computing
                      Machinery</i>, 2014, pp. 1151-1158. https://doi.org/10.1145/2638728.2641695.</p>
					</div>

					<!-- Footer -->
						<footer id="footer">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="3"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" /></li>
									</ul>
								</form>
							</section>
							<section class="split contact">
								<section>
									<h3>LinkedIn</h3>
										<p><a href="https://www.linkedin.com/in/kailani-woodard/">Kai'lani Woodard</a>
									</section>
								<section>
									<h3>GitHub</h3>
									<p><a href="https://github.com/kailaniwoodard">kailaniwoodard</a>
								</section>
								<section>
									<h3>Email</h3>
									<p><a href="#">woodardk@allegheny.edu</a></p>
								</section>
							</section>
						</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Kai'lani Woodard</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
